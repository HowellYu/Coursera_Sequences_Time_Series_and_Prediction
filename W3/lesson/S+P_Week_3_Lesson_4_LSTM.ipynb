{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S+P Week 3 Lesson 4 - LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D1J15Vh_1Jih",
        "colab": {}
      },
      "source": [
        "# !pip install tf-nightly-2.0-preview\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BOjujz601HcS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "02ce8986-1c6f-432b-f57d-af6d18a09144"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "print(sys.version)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9 (default, Jul 17 2020, 12:50:27) \n",
            "[GCC 8.4.0]\n",
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zswl7jRtGzkk",
        "colab": {}
      },
      "source": [
        "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
        "    plt.plot(time[start:end], series[start:end], format)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.grid(True)\n",
        "\n",
        "def trend(time, slope=0):\n",
        "    return slope * time\n",
        "\n",
        "def seasonal_pattern(season_time):\n",
        "    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n",
        "    return np.where(season_time < 0.4,\n",
        "                    np.cos(season_time * 2 * np.pi),\n",
        "                    1 / np.exp(3 * season_time))\n",
        "\n",
        "def seasonality(time, period, amplitude=1, phase=0):\n",
        "    \"\"\"Repeats the same pattern at each period\"\"\"\n",
        "    season_time = ((time + phase) % period) / period\n",
        "    return amplitude * seasonal_pattern(season_time)\n",
        "\n",
        "def noise(time, noise_level=1, seed=None):\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    return rnd.randn(len(time)) * noise_level\n",
        "\n",
        "time = np.arange(4 * 365 + 1, dtype=\"float32\")\n",
        "baseline = 10\n",
        "series = trend(time, 0.1)  \n",
        "baseline = 10\n",
        "amplitude = 40\n",
        "slope = 0.05\n",
        "noise_level = 5\n",
        "\n",
        "# Create the series\n",
        "series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n",
        "# Update with noise\n",
        "series += noise(time, noise_level, seed=42)\n",
        "\n",
        "split_time = 1000\n",
        "time_train = time[:split_time]\n",
        "x_train = series[:split_time]\n",
        "time_valid = time[split_time:]\n",
        "x_valid = series[split_time:]\n",
        "\n",
        "window_size = 20\n",
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4sTTIOCbyShY",
        "colab": {}
      },
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n",
        "  dataset = dataset.batch(batch_size).prefetch(1)\n",
        "  return dataset"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A1Hl39rklkLm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6f1ec19-86ef-4b4c-993e-5e511e7ae110"
      },
      "source": [
        "tf.keras.backend.clear_session() # clears any internal variable\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
        "optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(dataset, epochs=100, callbacks=[lr_schedule])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 21.5167 - mae: 22.0115\n",
            "Epoch 2/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 21.1522 - mae: 21.6444\n",
            "Epoch 3/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 20.7302 - mae: 21.2236\n",
            "Epoch 4/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 20.2834 - mae: 20.7757\n",
            "Epoch 5/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 19.7897 - mae: 20.2855\n",
            "Epoch 6/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 19.1782 - mae: 19.6696\n",
            "Epoch 7/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 18.2410 - mae: 18.7333\n",
            "Epoch 8/100\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 17.4825 - mae: 17.9748\n",
            "Epoch 9/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 17.1597 - mae: 17.6529\n",
            "Epoch 10/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 16.8547 - mae: 17.3463\n",
            "Epoch 11/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 16.5533 - mae: 17.0471\n",
            "Epoch 12/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 16.2565 - mae: 16.7524\n",
            "Epoch 13/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 15.9629 - mae: 16.4598\n",
            "Epoch 14/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 15.6593 - mae: 16.1548\n",
            "Epoch 15/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 15.3713 - mae: 15.8652\n",
            "Epoch 16/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 15.0752 - mae: 15.5697\n",
            "Epoch 17/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 14.7905 - mae: 15.2869\n",
            "Epoch 18/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 14.5229 - mae: 15.0178\n",
            "Epoch 19/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 14.2707 - mae: 14.7636\n",
            "Epoch 20/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 14.0293 - mae: 14.5217\n",
            "Epoch 21/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 13.8191 - mae: 14.3135\n",
            "Epoch 22/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 13.6084 - mae: 14.1032\n",
            "Epoch 23/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 13.4096 - mae: 13.9038\n",
            "Epoch 24/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 13.1859 - mae: 13.6794\n",
            "Epoch 25/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 12.9819 - mae: 13.4747\n",
            "Epoch 26/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 12.7278 - mae: 13.2184\n",
            "Epoch 27/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 12.4886 - mae: 12.9799\n",
            "Epoch 28/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 12.3459 - mae: 12.8362\n",
            "Epoch 29/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 11.9127 - mae: 12.4017\n",
            "Epoch 30/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 11.5934 - mae: 12.0835\n",
            "Epoch 31/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 11.2859 - mae: 11.7771\n",
            "Epoch 32/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 11.3520 - mae: 11.8418\n",
            "Epoch 33/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 10.5232 - mae: 11.0140\n",
            "Epoch 34/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 10.5483 - mae: 11.0364\n",
            "Epoch 35/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 10.0639 - mae: 10.5494\n",
            "Epoch 36/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 10.5303 - mae: 11.0200\n",
            "Epoch 37/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 10.1915 - mae: 10.6815\n",
            "Epoch 38/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 9.6502 - mae: 10.1381\n",
            "Epoch 39/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 9.1531 - mae: 9.6376\n",
            "Epoch 40/100\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 8.7075 - mae: 9.1934\n",
            "Epoch 41/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 8.2888 - mae: 8.7743\n",
            "Epoch 42/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 7.9466 - mae: 8.4313\n",
            "Epoch 43/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 7.6212 - mae: 8.1052\n",
            "Epoch 44/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 7.3689 - mae: 7.8547\n",
            "Epoch 45/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 7.1997 - mae: 7.6829\n",
            "Epoch 46/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 6.8836 - mae: 7.3661\n",
            "Epoch 47/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 6.6758 - mae: 7.1594\n",
            "Epoch 48/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 6.5791 - mae: 7.0609\n",
            "Epoch 49/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 6.2076 - mae: 6.6838\n",
            "Epoch 50/100\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 6.0389 - mae: 6.5179\n",
            "Epoch 51/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 5.9099 - mae: 6.3876\n",
            "Epoch 52/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 5.7769 - mae: 6.2586\n",
            "Epoch 53/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 5.6296 - mae: 6.1098\n",
            "Epoch 54/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 5.5207 - mae: 5.9948\n",
            "Epoch 55/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 5.3915 - mae: 5.8635\n",
            "Epoch 56/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 5.5568 - mae: 6.0306\n",
            "Epoch 57/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 5.2790 - mae: 5.7568\n",
            "Epoch 58/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 5.2576 - mae: 5.7360\n",
            "Epoch 59/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 5.1189 - mae: 5.5976\n",
            "Epoch 60/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 5.0482 - mae: 5.5221\n",
            "Epoch 61/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 5.3073 - mae: 5.7862\n",
            "Epoch 62/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 5.2209 - mae: 5.7006\n",
            "Epoch 63/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 5.0224 - mae: 5.4971\n",
            "Epoch 64/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 4.8378 - mae: 5.3121\n",
            "Epoch 65/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 5.2828 - mae: 5.7625\n",
            "Epoch 66/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 5.3684 - mae: 5.8518\n",
            "Epoch 67/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 6.1172 - mae: 6.5999\n",
            "Epoch 68/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 5.2448 - mae: 5.7288\n",
            "Epoch 69/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 5.4579 - mae: 5.9387\n",
            "Epoch 70/100\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 4.8784 - mae: 5.3517\n",
            "Epoch 71/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 5.8512 - mae: 6.3328\n",
            "Epoch 72/100\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 5.7091 - mae: 6.1906\n",
            "Epoch 73/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 6.5024 - mae: 6.9855\n",
            "Epoch 74/100\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 5.1171 - mae: 5.5983\n",
            "Epoch 75/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 5.4665 - mae: 5.9459\n",
            "Epoch 76/100\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 5.5865 - mae: 6.0675\n",
            "Epoch 77/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 6.6011 - mae: 7.0869\n",
            "Epoch 78/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 5.3414 - mae: 5.8222\n",
            "Epoch 79/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 5.3523 - mae: 5.8316\n",
            "Epoch 80/100\n",
            "31/31 [==============================] - 1s 30ms/step - loss: 5.1324 - mae: 5.6126\n",
            "Epoch 81/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 7.2442 - mae: 7.7277\n",
            "Epoch 82/100\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 5.2931 - mae: 5.7740\n",
            "Epoch 83/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 6.1063 - mae: 6.5905\n",
            "Epoch 84/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 8.0418 - mae: 8.5283\n",
            "Epoch 85/100\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 6.0476 - mae: 6.5356\n",
            "Epoch 86/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 7.0666 - mae: 7.5547\n",
            "Epoch 87/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 7.2429 - mae: 7.7278\n",
            "Epoch 88/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 6.3571 - mae: 6.8373\n",
            "Epoch 89/100\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 7.0662 - mae: 7.5513\n",
            "Epoch 90/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 7.5634 - mae: 8.0461\n",
            "Epoch 91/100\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 7.4016 - mae: 7.8897\n",
            "Epoch 92/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 10.3108 - mae: 10.8019\n",
            "Epoch 93/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 8.9524 - mae: 9.4390\n",
            "Epoch 94/100\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 9.0059 - mae: 9.4936\n",
            "Epoch 95/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 11.7405 - mae: 12.2335\n",
            "Epoch 96/100\n",
            "31/31 [==============================] - 1s 30ms/step - loss: 10.1950 - mae: 10.6860\n",
            "Epoch 97/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 7.8055 - mae: 8.2923\n",
            "Epoch 98/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 8.5342 - mae: 9.0218\n",
            "Epoch 99/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 8.4686 - mae: 8.9568\n",
            "Epoch 100/100\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 13.1609 - mae: 13.6531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AkBsrsXMzoWR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "3d9126fa-4506-491d-c6cd-c2126ec02e28"
      },
      "source": [
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-8, 1e-4, 0, 30])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1e-08, 0.0001, 0.0, 30.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4uh-97bpLZCA",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "   tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9),metrics=[\"mae\"])\n",
        "history = model.fit(dataset,epochs=500,verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "icGDaND7z0ne",
        "colab": {}
      },
      "source": [
        "forecast = []\n",
        "results = []\n",
        "for time in range(len(series) - window_size):\n",
        "  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n",
        "\n",
        "forecast = forecast[split_time-window_size:]\n",
        "results = np.array(forecast)[:, 0, 0]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plot_series(time_valid, x_valid)\n",
        "plot_series(time_valid, results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KfPeqI7rz4LD",
        "colab": {}
      },
      "source": [
        "tf.keras.metrics.mean_absolute_error(x_valid, results).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JUsdZB_tzDLe",
        "colab": {}
      },
      "source": [
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "mae=history.history['mae']\n",
        "loss=history.history['loss']\n",
        "\n",
        "epochs=range(len(loss)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot MAE and Loss\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, mae, 'r')\n",
        "plt.plot(epochs, loss, 'b')\n",
        "plt.title('MAE and Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"MAE\", \"Loss\"])\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "epochs_zoom = epochs[200:]\n",
        "mae_zoom = mae[200:]\n",
        "loss_zoom = loss[200:]\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot Zoomed MAE and Loss\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs_zoom, mae_zoom, 'r')\n",
        "plt.plot(epochs_zoom, loss_zoom, 'b')\n",
        "plt.title('MAE and Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"MAE\", \"Loss\"])\n",
        "\n",
        "plt.figure()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3CGaYFxXNEAK",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9))\n",
        "model.fit(dataset,epochs=100, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FJ3R8ysauz9e",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9))\n",
        "model.fit(dataset,epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}